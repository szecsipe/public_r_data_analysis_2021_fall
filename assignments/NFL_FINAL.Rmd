---
title: "NFL stats"
author: "Szécsi Péter"
date: "1/16/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(ggfortify)
```

## Introduction

In the chosen data table you can find statistics about NFL players. Every row contains data about one player in one match. My goal in this analysis is to create two plots and two regression models. To decide what my hypotheses and interest should be, lets explore the data!

```{r cars}
#Read the csv
raw <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018/2018-08-28/nfl_2010-2017.csv")[,-1]

view(raw)
#It was read in properly
```

## Data exploration and data cleaning

First I will check whether the data is what I think it is (variables look as they should look).
```{r}

##Date
hist(raw$game_year)
#There is a bump in the first column
table(raw$game_year)
#In the table you can see it is not problematic, probably the low number of breaks caused the problem
hist(raw$game_year, 25)
#better
```

Teams
```{r}
teams <- as.data.frame(table(raw$team))
view(teams)
```

There are more teams than there are currently in the NFL due to name changes (SD is LAC now; STL is LA now; OAK is LV today (I don't need to change if because they changed their name after 2017, but I do it anyway); JAC is the same as JAX, only the abb. changed)
Lets change it accordingly, in my following analyses continuity in franchises will be an important factor.

```{r}
raw <- raw %>%
  mutate(team = as.factor(case_when(team == "SD" ~ "LAC",
                                    team == "STL" ~ "LA",
                                    team == "OAK" ~ "LV",
                                    team == "JAC" ~ "JAX",
                                    TRUE ~ team)
                          )
         )
teams <- as.data.frame(table(raw$team))
view(teams)
```

Name
```{r}
#Look for reading mistakes
raw[which.max(nchar(raw$name)), "name"]
raw[which.min(nchar(raw$name)), "name"]
#Looks OK
```

Position
```{r}
table(raw$position)
```
There is enough data to analyze any position, I will check the corresponding performance metrics once I pick the position of interest

The variable which can be used as an outcome measure the best is rate (avg ratings of the player in the match), so I check that
```{r}
view(raw$rate)
sum(is.na(raw$rate))
hist(raw$rate, 1000)
```
There is a curiously high coloumn at 0 and somewhere around 40. Will need to check it.
The number of missing data is high (71044). I check whether it it similar in each position

```{r}
rated <- raw %>%
  filter(is.na(rate) == FALSE)

table(rated$position)
```
All of the QBs have ratings. I check whether the key performance mertics are filled out.
```{r}
qb <- rated %>%
  filter(position == "QB")
#Number of pass attempts
sum(is.na(qb$pass_att))
#Passed yards
sum(is.na(qb$pass_yds))
#Number of touchdown passes
sum(is.na(qb$pass_tds))
#Number of interceptions (when the pass is stolen by the opposing team)
sum(is.na(qb$int))
#Number of times the QB is tackled while having a ball in his hand (usually does not count as his fault)
sum(is.na(qb$sck))
#Number of times the ball gets stolen shortly before the QB releases the ball suring the passing movement
sum(is.na(qb$pass_fumbles))
```
The most important metrics contain 0 missing value which is great. There are some less important coloumns, but for some QBs they should be accounted for (depends on the player's style) 
```{r}
#Number of rush attempts
sum(is.na(qb$rush_att))
#Rushed yards
sum(is.na(qb$rush_yds))
#Number of touchdown rushes
sum(is.na(qb$rush_tds))
#AVerage rush distance
sum(is.na(qb$rush_avg))
#Number of times the ball gets stolen mid rush
sum(is.na(qb$rush_fumbles))
```
The number of missing values is the same in every case (1444) so probably they are missing in the same rows. I choose to exclude those rows to get a full picture about the QBs in my analysed sample

```{r}
#Choose cols if interest
qb <- qb %>%
  select(1:9, 15:21)

#Choose complete cases
qb <- qb[complete.cases(qb),]
```
More rows disappeared, but every remaining column need to be complete, and the number of coloumns is still enough
I check the distribution of the ratings again
```{r}
hist(qb$rate, 1000)
```
It looks much better, but I will need exclude the outliers (there are spikes at the end).

I use the 1.5*IQR criterion 
```{r}
qb_trimmed <- qb %>%
  filter(rate > quantile(qb$rate)[[2]] - 1.5*IQR(qb$rate) & 
         rate < quantile(qb$rate)[[3]] + 1.5*IQR(qb$rate))
hist(qb_trimmed$rate, 1000)
```
The distribution has a weird tale approaching 0, but otherwise looks great

# ##Research question
In this analysis I intend to explore what performance metrics can efficiently predics the ratings of the Quarterbacks (QBs). This question is not unique probably, because QBs are in the focus of the game and many fans think that the QB is the player who is mainly responsible for the success of the team. Sadly I can not test that hypothesis since I have no data available about the outcome of the games. I choose my research question to help the QBs of tomorrow. If they know what metrics (skills) they have to pay attention to have a higher rating they will have a greater chance to be drafted or be the crowd favorite.

First, I will build a model (m1) that contains only the key QB metrics (pass_yds, pass_tds, int). Second, I will build a model (m2) that contains the metrics that is contained by m1 and I add the metrics hybrid players are known for (rush_yds, rush_tds, rush_fumbles).

# ##Ploting
Before I start to test my hypotheses I produce two plots to know more about the QBs of these years.

First, I will check who were the most successful QBs in each team (I will only count those players who played at least 16 matches, which is the length of the regular season)

```{r}
MVP_dat <- qb_trimmed %>%
  group_by(team, name) %>%
  summarize(Rating = mean(rate), Matches = n(), SD = sd(rate)) %>%
  filter(Matches >=16) %>%
  group_by(team) %>%
  filter(Rating == max(Rating))

MVP <- ggplot(MVP_dat, aes(x = Rating, y = team)) +
  geom_text(aes(label = name), nudge_y = -0.5) +
  geom_point()+
  theme_light() +
  theme(panel.border = element_blank(), plot.title = element_text(hjust=0.5)) +
  xlim(82, 105) +
  labs(y = "",
       x = "Average ratings of preformance during his time on the team") +
  coord_cartesian(ylim = c(0,31)) +
  ggtitle(expression(atop("The Rating of the Highest Rated Player of each Franchise",
                    paste("(With a QB in the database who played at least 16 matches)"))))
MVP
```
The plot shows us that it does not mean the same to be the best in every team. You can even see that Peyton Manning managed to be the highest rated players of two teams (Denver and Indianapolis). Standard deviations of ratings were not added to the plot (I plot it below), they show that it is possible that these players do not differ statistically in their ratings.
```{r}
MVP_bars <- ggplot(MVP_dat, aes(x = Rating, y = team)) +
  geom_text(aes(label = name), nudge_y = -0.4) +
  geom_point()+
  theme_light() +
  geom_errorbarh(aes(xmax = Rating + SD, xmin = Rating - SD)) +
  theme(panel.border = element_blank(), plot.title = element_text(hjust=0.5)) +
  xlim(50, 150) +
  labs(y = "",
       x = "Average ratings of preformance during his time on the team") +
  coord_cartesian(ylim = c(0,31)) +
  ggtitle(expression(atop("The Rating of the Highest Rated Player of each Franchise",
                    paste("(With a QB in the database who played at least 16 matches)"))))
MVP_bars
```

The four most successful NFL teams are the Pittsburgh Steelers (PIT), the New England Patriots (NE), the San Francisco 49ers (SF), and the Dallas Cowboys (DAL). Lets look at the performance of those teams' QBs. It would be interesting to look at how efficiently those teams can use a pass attempt. This can be and indicator of how good they are at protecting the QB, catching the ball and creating safe receiving positions.


```{r}
top <- qb_trimmed %>%
  filter(team == "PIT" |
         team == "NE" |
         team == "SF" |
         team == "DAL")


top_pass <- ggplot(top, aes(x = pass_att, y = pass_yds, colour = team)) +
  geom_jitter()+
  theme_light() +
  theme(panel.border = element_blank(), plot.title = element_text(hjust=0.5)) +
  labs(y = "",
       x = "Average ratings of preformance during his time on the team") +
  ggtitle(expression(atop("The Rating of the Highest Rated Player of each Franchise",
                    paste("(With a QB in the database who played at least 16 matches)"))))
top_pass
```
There is no obvious pattern that would indicate difference between the teams. If there is difference, it is more subtle. Let's look at a boxplot showing the ratio of pass attempts and passed yards across the four top team.

```{r}
top <- top %>%
  mutate(success = pass_yds/pass_att)


top_success <- ggplot(top, aes(x = team, y = success)) +
  geom_boxplot()+
  theme_light() +
  theme(panel.border = element_blank(), plot.title = element_text(hjust=0.5)) +
  labs(y = "Ratio of the number of attempted passes and passed yards",
       x = "") +
  ggtitle("Ratio of attempted passes and passed yards in the historically top 4 teams") +
  scale_y_continuous(breaks = seq(0, 15, by = 2))
top_success
```
Indeed, based on the boxplots there is no difference between the teams.


To get familiar with the variables I will use I look at some of the relationships between them. First, I check whether the number of attempted passes and the attempted rushes have a inverse relationship.
```{r}
pass_rush <- ggplot(qb_trimmed, aes(x = rush_att, y = pass_att)) +
  geom_jitter() +
  geom_smooth()+
  theme_light() +
  theme(panel.border = element_blank(), plot.title = element_text(hjust=0.5)) +
  labs(y = "Pass attempts",
       x = "Rush attempts") +
  ggtitle("Relationship between the number of attempted passes and rushes")
pass_rush
```
Based on the plot we can say that there might be a weak relationship.

```{r}
cor.test(qb$rush_att, qb$pass_att, method = "spearman")
```
The relationship is weak, almost non-existent.


Secondly, I will check if those who take more risks and pass more interceptions, pass more yards.
```{r}
int_yds <- ggplot(qb_trimmed, aes(x = int, y = pass_yds)) +
  geom_jitter() +
  theme_light() +
  theme(panel.border = element_blank(), plot.title = element_text(hjust=0.5)) +
  labs(y = "Passed yards",
       x = "Number of interceptions") +
  ggtitle("Relationship between the number of passed yards and the number of interceptions")
int_yds
```


```{r}
cor.test(qb$pass_yds, qb$int, method = "pearson")
```
No relationship here either.

# ##Model fitting

As mentioned above in this section I will try to predict the rating of each players rating using the performance metrics. First, I will fit the more complex model.

```{r}
m2 <- lm(rate ~ pass_yds + pass_tds + int + rush_yds + rush_tds + rush_fumbles, data = qb_trimmed)
summary(m2)
```
The results of the model make sense, but I will talk about the results once I checked the assumptions.

#Overall picture
```{r}
autoplot(m2)
```
There are problems, Residuals vs Fitted and Q-Q plots and Scale-Location are not great

#Checking for influential outliers

```{r}
# ## Cook's distance check
cooksd <- cooks.distance(m2)
3*mean(cooksd)
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance, it is more or less ok
abline(h = 0.0010, col="red") #0.0010 as cutoff point based on the plot
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>0.0010, names(cooksd),""), col="red")
influential <- as.numeric(names(cooksd)[(cooksd > (0.0010))])

qb_filtered <- qb_trimmed[-influential, ]

#check whether it changes anything
m2_2 <- lm(rate ~ pass_yds + pass_tds + int + rush_yds + rush_tds + rush_fumbles, data = qb_filtered)
autoplot(m2_2)
#Each plot improved, I will continue to use this data
```

#Check the normality assumption.

```{r}
plot(m2_2, 2)
```
The Q-Q plot looks ok, It follows the line

#Linearity assumption

```{r}
plot(m2_2, 1)
```
There is a little difference between the red line and the middle line but it is not a great difference.

#Homoscedasticty

```{r}
plot(m2_2, 3)
lmtest::bptest(m2_2)
#the plot is showing a weak curve but based on the statistical test I choose not to worry about it
```

#Multicollinearity

```{r}
car::vif(m2_2)
#either or both cortisol measures should be excluded, I exclude cortisol salvia
```
No values are above 3, so I can say that my variables are independent of each other enough.

I am done with the first model, I will fit my less comlex model on the filtered data

```{r}
m1 <- lm(rate ~ pass_yds + pass_tds + int, data = qb_filtered)
summary(m1)
```

#Overall picture
```{r}
autoplot(m1)
```
These plots are very similiar to the more complex models plots. Based on these plots and the fact that every variable in this model is present in the more complex model, I decide that the assumptions don't need to be investigated further here.

#Model comparison
```{r}
AIC(m1)
AIC(m2_2)
BIC(m1)
BIC(m2_2)

lmtest::lrtest(m2_2, m1)
```











